<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving
and Interchange DTD v1.2 20190208//EN" "JATS-archivearticle1.dtd">

<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" dtd-version="1.2" article-type="other">

<front>


<article-meta>


<title-group>
<article-title>Tree object detection using airborne images and LiDAR
point clouds</article-title>
</title-group>

<contrib-group>
<contrib contrib-type="author" corresp="yes">
<name>
<surname>Bry</surname>
<given-names>Alexandre</given-names>
</name>
<string-name>Alexandre Bry</string-name>

<email>alexandre.bry.21@polytechnique.org</email>
<role vocab="https://credit.niso.org" vocab-term="writing – original
draft" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-original-draft/">writing</role>
<xref ref-type="aff" rid="aff-1">a</xref>
<xref ref-type="aff" rid="aff-2">b</xref>
<xref ref-type="corresp" rid="cor-1">&#x002A;</xref>
</contrib>
</contrib-group>
<aff id="aff-1">
<institution-wrap>
<institution>École polytechnique</institution>
</institution-wrap>

<city>Palaiseau</city>

<country>France</country>


<ext-link ext-link-type="uri" xlink:href="https://portail.polytechnique.edu/informatique/fr/page-daccueil">https://portail.polytechnique.edu/informatique/fr/page-daccueil</ext-link>
</aff>
<aff id="aff-2">
<institution content-type="dept">Research</institution>
<institution-wrap>
<institution>Geodan B.V.</institution>
</institution-wrap>

<city>Amsterdam</city>

<country>Netherlands</country>


<ext-link ext-link-type="uri" xlink:href="https://research.geodan.nl/">https://research.geodan.nl/</ext-link>
</aff>
<author-notes>
<corresp id="cor-1">alexandre.bry.21@polytechnique.org</corresp>
</author-notes>









<history></history>


<abstract>
<p>This is the abstract. It can be on multiple lines and contain
<bold>Markdown</bold>.</p>
</abstract>
<kwd-group kwd-group-type="author">
<kwd>tree detection</kwd>
<kwd>deep learning</kwd>
</kwd-group>




</article-meta>

</front>

<body>
<sec id="introduction">
  <title>Introduction</title>
  <p>The goal of the internship was to study the possibility of
  combining LiDAR point clouds and aerial images in a deep learning
  model to perform instance segmentation of trees. The two types of data
  are indeed complementary, as point clouds capture the shape of the
  worlds, while images capture the colors. However, combining them into
  a format that allows a model to handle them simultaneously is not an
  easy task because they inherently have a very different spatial
  repartition and encoding.</p>
  <p>The second major topic of the internship was to acquire a proper
  dataset matching all the criteria required for the project. Most of
  the datasets containing tree annotations only used either RGB images
  or LiDAR point clouds, but not both. Therefore, I had to create such a
  dataset by myself, using the openly available images and point clouds
  in the Netherlands, by annotating trees by hand to properly train and
  evaluate the methods.</p>
</sec>
<sec id="state-of-the-art">
  <title>State-of-the-art</title>
  <sec id="datasets">
    <title>Datasets</title>
    <sec id="computer-vision-tasks">
      <title>Computer vision tasks</title>
      <p>Difference between object detection and instance segmentation.
      The first on is easier to train because it only requires bounding
      boxes</p>
    </sec>
    <sec id="requirements">
      <title>Requirements</title>
      <p>Before presenting the different promising datasets and the
      reasons why they were not fully usable for the project, let’s
      enumerate the different conditions and requirements for the tree
      instance segmentation task:</p>
      <list list-type="bullet">
        <list-item>
          <p>Multiple types of data:</p>
          <list list-type="bullet">
            <list-item>
              <p>Aerial RGB images</p>
            </list-item>
            <list-item>
              <p>LiDAR point clouds (preferably aerial)</p>
            </list-item>
            <list-item>
              <p>(Optional) Aerial infrared images</p>
            </list-item>
          </list>
        </list-item>
        <list-item>
          <p>Tree crown annotations or bounding boxes</p>
        </list-item>
        <list-item>
          <p>High-enough resolution:</p>
          <list list-type="bullet">
            <list-item>
              <p>For images, about 25 cm</p>
            </list-item>
            <list-item>
              <p>For point clouds, about 10 cm</p>
            </list-item>
          </list>
        </list-item>
      </list>
      <p>Here are the explanations for these requirements. As for the
      types of data, RGB images and point clouds are required to
      experiment on the ability of the model to combine the two very
      different kinds of information they hold. Having infrared data as
      well could be beneficial, but it was not necessary. Regarding tree
      annotations, it was necessary to have a way to spatially identify
      them individually, using crown contours or simply bounding boxes.
      Since the model outputs bounding boxes, any kind of other format
      could easily be transformed to bounding boxes. Finally, the
      resolution had to be high enough to identify individual trees and
      be able to really use the data. For the point clouds especially,
      the whole idea was to see if and how the topology of the trees
      could be learnt, using at least the trunks and even the biggest
      branches if possible. Therefore, even if they are not really
      comparable, this is the reason why the required resolution is more
      precise for the point clouds.</p>
      <p>Unfortunately, none of the datasets that I found matched all
      these criteria. Furthermore, I didn’t find any overlapping
      datasets that I could merge to create a dataset with all the
      required types of data. In the next parts, I will go through the
      different kinds of datasets that exist, the reasons why they did
      not really fit for the project and the ideas I got when searching
      for a way to use them.</p>
    </sec>
    <sec id="existing-tree-datasets">
      <title>Existing tree datasets</title>
      <p>As explained above, there were quite a lot of requirements to
      fulfill to have a complete dataset usable for the task. This means
      that almost all the available datasets were missing something, as
      they were mainly focusing on using one kind of data and trying to
      make the most out of it, instead of trying to use all the types of
      data together.</p>
      <p>The most comprehensive list of tree annotations datasets was
      published in Ouaknine et al.
      (<xref alt="2023" rid="ref-OpenForest" ref-type="bibr">2023</xref>).
      Bountos, Ouaknine, and Rolnick
      (<xref alt="2023" rid="ref-FoMo-Bench" ref-type="bibr">2023</xref>)
      also lists several interesting datasets, even though most of them
      can also be found in Ouaknine et al.
      (<xref alt="2023" rid="ref-OpenForest" ref-type="bibr">2023</xref>).
      Without enumerating all of them, there were multiple kinds of
      datasets that all have their own flaws regarding the requirements
      I was looking for.</p>
      <p>Firstly, there are the forest inventories. Jucker et al.
      (<xref alt="2022" rid="ref-TALLO" ref-type="bibr">2022</xref>) is
      probably the most interesting one in this category, because it
      contains a lot of spatial information about almost 500K trees,
      with their locations, their crown radii and their heights.
      Therefore, everything needed to localize trees is in the dataset.
      However, I didn’t manage to find RGB images or LiDAR point clouds
      of the areas where the trees are located, making it impossible to
      use these annotations to train tree detection.</p>
      <p>Secondly, there are the RGB datasets. Reiersen et al.
      (<xref alt="2022" rid="ref-ReforesTree" ref-type="bibr">2022</xref>)
      and B. Weinstein
      (<xref alt="2023" rid="ref-MillionTrees" ref-type="bibr">2023</xref>)
      are two of them and the quality of their images are high. The only
      drawback of these datasets is obviously that they don’t provide
      any kind of point cloud, which make them unsuitable for the
      task.</p>
      <p>Thirdly, there are the LiDAR datasets, such as Kalinicheva et
      al.
      (<xref alt="2022" rid="ref-WildForest3D" ref-type="bibr">2022</xref>)
      and Puliti et al.
      (<xref alt="2023" rid="ref-FOR-instance" ref-type="bibr">2023</xref>).
      Similarly to RGB datasets, they lack one of the data source for
      the task I worked on. But unlike them, they have the advantage
      that the missing data could be much easier to acquire from another
      source, since RGB aerial or satellite images are much more common
      than LiDAR point clouds. However, this solution was abandoned for
      two main reasons. First it is quite challenging to find the exact
      locations where the point clouds were acquired. Then, even when
      the location is known, it is often in the middle of a forest where
      the quality of satellite imagery is very low.</p>
      <p>Finally, I also found two datasets that had RGB and LiDAR
      components. The first one is Hu et al.
      (<xref alt="2023" rid="ref-MDAS" ref-type="bibr">2023</xref>).
      This benchmark dataset encompasses RGB images, hyperspectral
      images and Digital Surface Models (DSM). There were however two
      major flaws. The obvious one was that this dataset was created
      with land semantic segmentation tasks in mind, so there was no
      tree annotations. The less obvious one was that a DSM is not a
      point cloud, even though it is some kind of 3D information and was
      often created using a LiDAR point cloud. As a consequence, I would
      have been very limited in my ability to use the point cloud.</p>
      <p>The only real dataset with RGB and LiDAR was B. G. Weinstein et
      al. (<xref alt="2019" rid="ref-NEON" ref-type="bibr">2019</xref>).
      This dataset contains exactly all the data I was looking for, with
      RGB images, hyperspectral images and LiDAR point clouds. With
      30975 tree annotations, it is also a quite large dataset, spanning
      across multiple various forests. The reason why I decided not to
      use it despite all this is that at the beginning of the project, I
      thought that the quality of the images and the point clouds was
      too low. Looking back on this decision, I think that I probably
      could have worked with this dataset and gotten great results. This
      would have saved me the time spent annotating the trees for my own
      dataset, which I will talk more about later. My decision was also
      influenced by the quality of the images and the point clouds
      available in the Netherlands, which I will talk about in the next
      section.</p>
    </sec>
    <sec id="public-data">
      <title>Public data</title>
      <p>After rejecting all the available datasets I had found, the
      only solution I had left was to create my own dataset. I won’t
      dive too much in this process that I will explain in
      <xref alt="Section 3" rid="sec-dataset">Section 3</xref>. I just
      want to mention all the publicly available datasets that I used or
      could have used to create this custom dataset.</p>
      <p>For practical reasons, the two countries where I mostly
      searched for available data are France and the Netherlands. I was
      looking for three different data types independently:</p>
      <list list-type="bullet">
        <list-item>
          <p>RGB (and eventually infrared) images</p>
        </list-item>
        <list-item>
          <p>LiDAR point clouds</p>
        </list-item>
        <list-item>
          <p>Tree annotations</p>
        </list-item>
      </list>
      <p>These three types of data are available in similar ways in both
      countries, although the Netherlands have a small edge over France.
      RGB images are really easy to find in France (Institut national de
      l’information géographique et forestière (IGN)
      (<xref alt="2021" rid="ref-IGN_BDORTHO" ref-type="bibr">2021</xref>))
      and in the Netherlands (Beeldmateriaal Nederland
      (<xref alt="2024" rid="ref-Luchtfotos" ref-type="bibr">2024</xref>)),
      but the resolution is better in the Netherlands (8 cm vs 20 cm).
      Hyperspectral images are also available in both countries,
      although for those the resolution is only 25 cm in the
      Netherlands.</p>
      <p>As for LiDAR point clouds, the Netherlands have a small edge
      over France, because they are at their forth version covering the
      whole country with Actueel Hoogtebestand Nederland
      (<xref alt="2020" rid="ref-AHN4" ref-type="bibr">2020</xref>), and
      are already working on the fifth version. In France, data
      acquisition for the first LiDAR point cloud covering the whole
      country (Institut national de l’information géographique et
      forestière (IGN)
      (<xref alt="2020" rid="ref-IGN_LiDARHD" ref-type="bibr">2020</xref>))
      started a few years ago. It is not yet finished, even though data
      is already available for half of the country. The other advantage
      of the data from Netherlands regarding LiDAR point clouds is that
      all flights are performed during winter, which allows light beams
      to penetrate more deeply in trees and reach trunks and branches.
      This is not the case in France.</p>
      <p>The part that is missing in both countries is related to tree
      annotations. Many municipalities have datasets containing
      information about all the public trees they handle. This is for
      example the case for Gemeente Amsterdam
      (<xref alt="2024" rid="ref-amsterdam_trees" ref-type="bibr">2024</xref>)
      and Bordeaux Métropole
      (<xref alt="2024" rid="ref-bordeaux_trees" ref-type="bibr">2024</xref>).
      However, these datasets cannot really be used as ground truth for
      a custom dataset for several reasons. First, many of them do not
      contain coordinates indicating the position of each tree in the
      city. Then, even those that contain coordinates are most of the
      time missing any kind of information allowing to deduce a bounding
      box for the tree crowns. Finally, even if they did contain
      everything, they only focus on public trees, and are missing every
      single tree located in a private area. Since public and private
      areas are obviously imbricated in all cities, it means that any
      area we try to train the model on would be missing all the private
      trees, making the training process impossible.</p>
    </sec>
    <sec id="dataset-augmentation-techniques">
      <title>Dataset augmentation techniques</title>
    </sec>
  </sec>
  <sec id="models">
    <title>Models</title>
  </sec>
</sec>
<sec id="sec-dataset">
  <title>Dataset</title>
</sec>
<sec id="model">
  <title>Model</title>
</sec>
<sec id="results">
  <title>Results</title>
  <p>Beyond mAP: Jena et al.
  (<xref alt="2023" rid="ref-BeyondMAP" ref-type="bibr">2023</xref>)</p>
</sec>
<sec id="conclusion">
  <title>Conclusion</title>
  <p>Blablabla</p>
</sec>
</body>

<back>
<ref-list>
  <title></title>
  <ref id="ref-FoMo-Bench">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Bountos</surname><given-names>Nikolaos Ioannis</given-names></name>
        <name><surname>Ouaknine</surname><given-names>Arthur</given-names></name>
        <name><surname>Rolnick</surname><given-names>David</given-names></name>
      </person-group>
      <article-title>FoMo-bench: A multi-modal, multi-scale and multi-task forest monitoring benchmark for remote sensing foundation models</article-title>
      <source>arXiv preprint arXiv:2312.10114</source>
      <year iso-8601-date="2023">2023</year>
      <uri>https://arxiv.org/abs/2312.10114</uri>
    </element-citation>
  </ref>
  <ref id="ref-OpenForest">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Ouaknine</surname><given-names>Arthur</given-names></name>
        <name><surname>Kattenborn</surname><given-names>Teja</given-names></name>
        <name><surname>Laliberté</surname><given-names>Etienne</given-names></name>
        <name><surname>Rolnick</surname><given-names>David</given-names></name>
      </person-group>
      <article-title>OpenForest: A data catalogue for machine learning in forest monitoring</article-title>
      <year iso-8601-date="2023">2023</year>
      <uri>https://arxiv.org/abs/2311.00277</uri>
    </element-citation>
  </ref>
  <ref id="ref-NEON">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Weinstein</surname><given-names>Ben G.</given-names></name>
        <name><surname>Marconi</surname><given-names>Sergio</given-names></name>
        <name><surname>Bohlman</surname><given-names>Stephanie</given-names></name>
        <name><surname>Zare</surname><given-names>Alina</given-names></name>
        <name><surname>White</surname><given-names>Ethan</given-names></name>
      </person-group>
      <article-title>Individual tree-crown detection in RGB imagery using semi-supervised deep learning neural networks</article-title>
      <source>Remote Sensing</source>
      <year iso-8601-date="2019">2019</year>
      <volume>11</volume>
      <issue>11</issue>
      <issn>2072-4292</issn>
      <uri>https://www.mdpi.com/2072-4292/11/11/1309</uri>
      <pub-id pub-id-type="doi">10.3390/rs11111309</pub-id>
    </element-citation>
  </ref>
  <ref id="ref-ReforesTree">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Reiersen</surname><given-names>Gyri</given-names></name>
        <name><surname>Dao</surname><given-names>David</given-names></name>
        <name><surname>Lütjens</surname><given-names>Björn</given-names></name>
        <name><surname>Klemmer</surname><given-names>Konstantin</given-names></name>
        <name><surname>Amara</surname><given-names>Kenza</given-names></name>
        <name><surname>Steinegger</surname><given-names>Attila</given-names></name>
        <name><surname>Zhang</surname><given-names>Ce</given-names></name>
        <name><surname>Zhu</surname><given-names>Xiaoxiang</given-names></name>
      </person-group>
      <article-title>ReforesTree: A dataset for estimating tropical forest carbon stock with deep learning and aerial imagery</article-title>
      <year iso-8601-date="2022">2022</year>
      <uri>https://arxiv.org/abs/2201.11192</uri>
    </element-citation>
  </ref>
  <ref id="ref-FOR-instance">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Puliti</surname><given-names>Stefano</given-names></name>
        <name><surname>Pearse</surname><given-names>Grant</given-names></name>
        <name><surname>Surový</surname><given-names>Peter</given-names></name>
        <name><surname>Wallace</surname><given-names>Luke</given-names></name>
        <name><surname>Hollaus</surname><given-names>Markus</given-names></name>
        <name><surname>Wielgosz</surname><given-names>Maciej</given-names></name>
        <name><surname>Astrup</surname><given-names>Rasmus</given-names></name>
      </person-group>
      <article-title>FOR-instance: A UAV laser scanning benchmark dataset for semantic and instance segmentation of individual trees</article-title>
      <year iso-8601-date="2023">2023</year>
      <uri>https://arxiv.org/abs/2309.01279</uri>
    </element-citation>
  </ref>
  <ref id="ref-MDAS">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Hu</surname><given-names>J.</given-names></name>
        <name><surname>Liu</surname><given-names>R.</given-names></name>
        <name><surname>Hong</surname><given-names>D.</given-names></name>
        <name><surname>Camero</surname><given-names>A.</given-names></name>
        <name><surname>Yao</surname><given-names>J.</given-names></name>
        <name><surname>Schneider</surname><given-names>M.</given-names></name>
        <name><surname>Kurz</surname><given-names>F.</given-names></name>
        <name><surname>Segl</surname><given-names>K.</given-names></name>
        <name><surname>Zhu</surname><given-names>X. X.</given-names></name>
      </person-group>
      <article-title>MDAS: A new multimodal benchmark dataset for remote sensing</article-title>
      <source>Earth System Science Data</source>
      <year iso-8601-date="2023">2023</year>
      <volume>15</volume>
      <issue>1</issue>
      <uri>https://essd.copernicus.org/articles/15/113/2023/</uri>
      <pub-id pub-id-type="doi">10.5194/essd-15-113-2023</pub-id>
      <fpage>113</fpage>
      <lpage>131</lpage>
    </element-citation>
  </ref>
  <ref id="ref-TALLO">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Jucker</surname><given-names>Tommaso</given-names></name>
        <name><surname>Fischer</surname><given-names>Fabian Jörg</given-names></name>
        <name><surname>Chave</surname><given-names>Jérôme</given-names></name>
        <name><surname>Coomes</surname><given-names>David A.</given-names></name>
        <name><surname>Caspersen</surname><given-names>John</given-names></name>
        <name><surname>Ali</surname><given-names>Arshad</given-names></name>
        <name><surname>Loubota Panzou</surname><given-names>Grace Jopaul</given-names></name>
        <name><surname>Feldpausch</surname><given-names>Ted R.</given-names></name>
        <name><surname>Falster</surname><given-names>Daniel</given-names></name>
        <name><surname>Usoltsev</surname><given-names>Vladimir A.</given-names></name>
        <name><surname>Adu-Bredu</surname><given-names>Stephen</given-names></name>
        <name><surname>Alves</surname><given-names>Luciana F.</given-names></name>
        <name><surname>Aminpour</surname><given-names>Mohammad</given-names></name>
        <name><surname>Angoboy</surname><given-names>Ilondea B.</given-names></name>
        <name><surname>Anten</surname><given-names>Niels P. R.</given-names></name>
        <name><surname>Antin</surname><given-names>Cécile</given-names></name>
        <name><surname>Askari</surname><given-names>Yousef</given-names></name>
        <name><surname>Muñoz</surname><given-names>Rodrigo</given-names></name>
        <name><surname>Ayyappan</surname><given-names>Narayanan</given-names></name>
        <name><surname>Balvanera</surname><given-names>Patricia</given-names></name>
        <name><surname>Banin</surname><given-names>Lindsay</given-names></name>
        <name><surname>Barbier</surname><given-names>Nicolas</given-names></name>
        <name><surname>Battles</surname><given-names>John J.</given-names></name>
        <name><surname>Beeckman</surname><given-names>Hans</given-names></name>
        <name><surname>Bocko</surname><given-names>Yannick E.</given-names></name>
        <name><surname>Bond-Lamberty</surname><given-names>Ben</given-names></name>
        <name><surname>Bongers</surname><given-names>Frans</given-names></name>
        <name><surname>Bowers</surname><given-names>Samuel</given-names></name>
        <name><surname>Brade</surname><given-names>Thomas</given-names></name>
        <name><surname>Breugel</surname><given-names>Michiel van</given-names></name>
        <name><surname>Chantrain</surname><given-names>Arthur</given-names></name>
        <name><surname>Chaudhary</surname><given-names>Rajeev</given-names></name>
        <name><surname>Dai</surname><given-names>Jingyu</given-names></name>
        <name><surname>Dalponte</surname><given-names>Michele</given-names></name>
        <name><surname>Dimobe</surname><given-names>Kangbéni</given-names></name>
        <name><surname>Domec</surname><given-names>Jean-Christophe</given-names></name>
        <name><surname>Doucet</surname><given-names>Jean-Louis</given-names></name>
        <name><surname>Duursma</surname><given-names>Remko A.</given-names></name>
        <name><surname>Enríquez</surname><given-names>Moisés</given-names></name>
        <name><surname>Ewijk</surname><given-names>Karin Y. van</given-names></name>
        <name><surname>Farfán-Rios</surname><given-names>William</given-names></name>
        <name><surname>Fayolle</surname><given-names>Adeline</given-names></name>
        <name><surname>Forni</surname><given-names>Eric</given-names></name>
        <name><surname>Forrester</surname><given-names>David I.</given-names></name>
        <name><surname>Gilani</surname><given-names>Hammad</given-names></name>
        <name><surname>Godlee</surname><given-names>John L.</given-names></name>
        <name><surname>Gourlet-Fleury</surname><given-names>Sylvie</given-names></name>
        <name><surname>Haeni</surname><given-names>Matthias</given-names></name>
        <name><surname>Hall</surname><given-names>Jefferson S.</given-names></name>
        <name><surname>He</surname><given-names>Jie-Kun</given-names></name>
        <name><surname>Hemp</surname><given-names>Andreas</given-names></name>
        <name><surname>Hernández-Stefanoni</surname><given-names>José L.</given-names></name>
        <name><surname>Higgins</surname><given-names>Steven I.</given-names></name>
        <name><surname>Holdaway</surname><given-names>Robert J.</given-names></name>
        <name><surname>Hussain</surname><given-names>Kiramat</given-names></name>
        <name><surname>Hutley</surname><given-names>Lindsay B.</given-names></name>
        <name><surname>Ichie</surname><given-names>Tomoaki</given-names></name>
        <name><surname>Iida</surname><given-names>Yoshiko</given-names></name>
        <name><surname>Jiang</surname><given-names>Hai-sheng</given-names></name>
        <name><surname>Joshi</surname><given-names>Puspa Raj</given-names></name>
        <name><surname>Kaboli</surname><given-names>Hasan</given-names></name>
        <name><surname>Larsary</surname><given-names>Maryam Kazempour</given-names></name>
        <name><surname>Kenzo</surname><given-names>Tanaka</given-names></name>
        <name><surname>Kloeppel</surname><given-names>Brian D.</given-names></name>
        <name><surname>Kohyama</surname><given-names>Takashi</given-names></name>
        <name><surname>Kunwar</surname><given-names>Suwash</given-names></name>
        <name><surname>Kuyah</surname><given-names>Shem</given-names></name>
        <name><surname>Kvasnica</surname><given-names>Jakub</given-names></name>
        <name><surname>Lin</surname><given-names>Siliang</given-names></name>
        <name><surname>Lines</surname><given-names>Emily R.</given-names></name>
        <name><surname>Liu</surname><given-names>Hongyan</given-names></name>
        <name><surname>Lorimer</surname><given-names>Craig</given-names></name>
        <name><surname>Loumeto</surname><given-names>Jean-Joël</given-names></name>
        <name><surname>Malhi</surname><given-names>Yadvinder</given-names></name>
        <name><surname>Marshall</surname><given-names>Peter L.</given-names></name>
        <name><surname>Mattsson</surname><given-names>Eskil</given-names></name>
        <name><surname>Matula</surname><given-names>Radim</given-names></name>
        <name><surname>Meave</surname><given-names>Jorge A.</given-names></name>
        <name><surname>Mensah</surname><given-names>Sylvanus</given-names></name>
        <name><surname>Mi</surname><given-names>Xiangcheng</given-names></name>
        <name><surname>Momo</surname><given-names>Stéphane</given-names></name>
        <name><surname>Moncrieff</surname><given-names>Glenn R.</given-names></name>
        <name><surname>Mora</surname><given-names>Francisco</given-names></name>
        <name><surname>Nissanka</surname><given-names>Sarath P.</given-names></name>
        <name><surname>O’Hara</surname><given-names>Kevin L.</given-names></name>
        <name><surname>Pearce</surname><given-names>Steven</given-names></name>
        <name><surname>Pelissier</surname><given-names>Raphaël</given-names></name>
        <name><surname>Peri</surname><given-names>Pablo L.</given-names></name>
        <name><surname>Ploton</surname><given-names>Pierre</given-names></name>
        <name><surname>Poorter</surname><given-names>Lourens</given-names></name>
        <name><surname>Pour</surname><given-names>Mohsen Javanmiri</given-names></name>
        <name><surname>Pourbabaei</surname><given-names>Hassan</given-names></name>
        <name><surname>Dupuy-Rada</surname><given-names>Juan Manuel</given-names></name>
        <name><surname>Ribeiro</surname><given-names>Sabina C.</given-names></name>
        <name><surname>Ryan</surname><given-names>Casey</given-names></name>
        <name><surname>Sanaei</surname><given-names>Anvar</given-names></name>
        <name><surname>Sanger</surname><given-names>Jennifer</given-names></name>
        <name><surname>Schlund</surname><given-names>Michael</given-names></name>
        <name><surname>Sellan</surname><given-names>Giacomo</given-names></name>
        <name><surname>Shenkin</surname><given-names>Alexander</given-names></name>
        <name><surname>Sonké</surname><given-names>Bonaventure</given-names></name>
        <name><surname>Sterck</surname><given-names>Frank J.</given-names></name>
        <name><surname>Svátek</surname><given-names>Martin</given-names></name>
        <name><surname>Takagi</surname><given-names>Kentaro</given-names></name>
        <name><surname>Trugman</surname><given-names>Anna T.</given-names></name>
        <name><surname>Ullah</surname><given-names>Farman</given-names></name>
        <name><surname>Vadeboncoeur</surname><given-names>Matthew A.</given-names></name>
        <name><surname>Valipour</surname><given-names>Ahmad</given-names></name>
        <name><surname>Vanderwel</surname><given-names>Mark C.</given-names></name>
        <name><surname>Vovides</surname><given-names>Alejandra G.</given-names></name>
        <name><surname>Wang</surname><given-names>Weiwei</given-names></name>
        <name><surname>Wang</surname><given-names>Li-Qiu</given-names></name>
        <name><surname>Wirth</surname><given-names>Christian</given-names></name>
        <name><surname>Woods</surname><given-names>Murray</given-names></name>
        <name><surname>Xiang</surname><given-names>Wenhua</given-names></name>
        <name><surname>Ximenes</surname><given-names>Fabiano de Aquino</given-names></name>
        <name><surname>Xu</surname><given-names>Yaozhan</given-names></name>
        <name><surname>Yamada</surname><given-names>Toshihiro</given-names></name>
        <name><surname>Zavala</surname><given-names>Miguel A.</given-names></name>
      </person-group>
      <article-title>Tallo: A global tree allometry and crown architecture database</article-title>
      <source>Global Change Biology</source>
      <year iso-8601-date="2022">2022</year>
      <volume>28</volume>
      <issue>17</issue>
      <uri>https://onlinelibrary.wiley.com/doi/abs/10.1111/gcb.16302</uri>
      <pub-id pub-id-type="doi">https://doi.org/10.1111/gcb.16302</pub-id>
      <fpage>5254</fpage>
      <lpage>5268</lpage>
    </element-citation>
  </ref>
  <ref id="ref-MillionTrees">
    <element-citation publication-type="webpage">
      <person-group person-group-type="author">
        <name><surname>Weinstein</surname><given-names>Ben</given-names></name>
      </person-group>
      <article-title>MillionTrees</article-title>
      <year iso-8601-date="2023">2023</year>
      <date-in-citation content-type="access-date"><year iso-8601-date="2024-07-08">2024</year><month>07</month><day>08</day></date-in-citation>
      <uri>https://milliontrees.idtrees.org/</uri>
    </element-citation>
  </ref>
  <ref id="ref-WildForest3D">
    <element-citation>
      <person-group person-group-type="author">
        <name><surname>Kalinicheva</surname><given-names>Ekaterina</given-names></name>
        <name><surname>Landrieu</surname><given-names>Loic</given-names></name>
        <name><surname>Mallet</surname><given-names>Clément</given-names></name>
        <name><surname>Chehata</surname><given-names>Nesrine</given-names></name>
      </person-group>
      <article-title>Multi-layer modeling of dense vegetation from aerial LiDAR scans</article-title>
      <year iso-8601-date="2022">2022</year>
      <uri>https://arxiv.org/abs/2204.11620</uri>
    </element-citation>
  </ref>
  <ref id="ref-BeyondMAP">
    <element-citation publication-type="article-journal">
      <person-group person-group-type="author">
        <name><surname>Jena</surname><given-names>Rohit</given-names></name>
        <name><surname>Zhornyak</surname><given-names>Lukas</given-names></name>
        <name><surname>Doiphode</surname><given-names>Nehal</given-names></name>
        <name><surname>Chaudhari</surname><given-names>Pratik</given-names></name>
        <name><surname>Buch</surname><given-names>Vivek</given-names></name>
        <name><surname>Gee</surname><given-names>James</given-names></name>
        <name><surname>Shi</surname><given-names>Jianbo</given-names></name>
      </person-group>
      <article-title>Beyond mAP: Towards better evaluation of instance segmentation</article-title>
      <source>CVPR</source>
      <year iso-8601-date="2023">2023</year>
    </element-citation>
  </ref>
  <ref id="ref-AHN4">
    <element-citation>
      <person-group person-group-type="author">
        <string-name>Actueel Hoogtebestand Nederland</string-name>
      </person-group>
      <article-title>AHN4 - Actual Height Model of the Netherlands</article-title>
      <year iso-8601-date="2020">2020</year>
      <uri>https://www.ahn.nl/</uri>
    </element-citation>
  </ref>
  <ref id="ref-Luchtfotos">
    <element-citation>
      <person-group person-group-type="author">
        <string-name>Beeldmateriaal Nederland</string-name>
      </person-group>
      <article-title>Luchtfoto’s (Aerial Photographs)</article-title>
      <year iso-8601-date="2024">2024</year>
      <uri>https://www.beeldmateriaal.nl/luchtfotos</uri>
    </element-citation>
  </ref>
  <ref id="ref-IGN_LiDARHD">
    <element-citation>
      <person-group person-group-type="author">
        <string-name>Institut national de l’information géographique et forestière (IGN)</string-name>
      </person-group>
      <article-title>LiDAR HD</article-title>
      <year iso-8601-date="2020">2020</year>
      <uri>https://geoservices.ign.fr/lidarhd</uri>
    </element-citation>
  </ref>
  <ref id="ref-IGN_BDORTHO">
    <element-citation>
      <person-group person-group-type="author">
        <string-name>Institut national de l’information géographique et forestière (IGN)</string-name>
      </person-group>
      <article-title>BD ORTHO</article-title>
      <year iso-8601-date="2021">2021</year>
      <uri>https://geoservices.ign.fr/bdortho</uri>
    </element-citation>
  </ref>
  <ref id="ref-amsterdam_trees">
    <element-citation>
      <person-group person-group-type="author">
        <string-name>Gemeente Amsterdam</string-name>
      </person-group>
      <article-title>Bomenbestand Amsterdam (Amsterdam Tree Dataset)</article-title>
      <year iso-8601-date="2024">2024</year>
      <uri>https://maps.amsterdam.nl/open_geodata/?k=505</uri>
    </element-citation>
  </ref>
  <ref id="ref-bordeaux_trees">
    <element-citation>
      <person-group person-group-type="author">
        <string-name>Bordeaux Métropole</string-name>
      </person-group>
      <article-title>Patrimoine arboré de Bordeaux Métropole (Tree Heritage of Bordeaux Metropole)</article-title>
      <year iso-8601-date="2024">2024</year>
      <uri>https://opendata.bordeaux-metropole.fr/explore/dataset/ec_arbre_p/information/?disjunctive.insee</uri>
    </element-citation>
  </ref>
</ref-list>
</back>



</article>